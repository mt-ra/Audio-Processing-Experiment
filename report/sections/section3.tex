\section{Implementing a FIR Convolution filter}

\subsection{Linear, time-invariant systems}
For every possible input signal $x$, a system $H$ maps it to an output signal $H(x) = y$.

\begin{center}\input{assets/system.tex}\end{center}
A linear system is one which satisfies the superposition and scaling properties:

\textbf{Superposition property:}\\
A system $H$ satisfies the superposition property if applying the system to a sum
of two signals $x_1$ and $x_2$ is equivalent to applying the system to the two signals,
and then summing the results.
$$H(x_1 + x_2) = H(x_1) + H(x_2)$$

\textbf{Scaling Property:}\\
A system $H$ satisfies the scaling property if applying a system to a signal that is scaled by a factor
is equivalent to first applying the system to the signal and then scaling the result by that factor.
$$H(\lambda x_1) = \lambda H(x_1)$$


\textbf{Time-invariance property:}\\
A system is time invariant if shifting the input signal in time and then
applying the system gives an output equivalent to if you first apply the system, 
and then shift the result in time.

\begin{center}\input{assets/shift.tex}\end{center}

A system that is both linear and time-invariant is called a LTI system.

\pagebreak 

\subsection{Impulse response}
The impulse response of a $h$ system is the output when the system is applied to the delta function $\delta$.
$$h = H(\delta)$$

\begin{center}\input{assets/impulse_response.tex}\end{center}
Since any input signal is a sum of scaled and shifted delta functions, applying an 
LTI system to an input signal is equivalent to taking the corresponding scalings and 
shifts of the impulse response and adding them together. 
Thus an LTI system can be completely described by its impulse response.

\begin{center}\input{assets/linearity.tex}\end{center}

Thus it's easy to see that applying an LTI system onto a signal is equivalent to 
convolving the signal with the impulse response of the system.

\subsection{Response of Sinusoids}
When a sinusoid is fed through an LTI system, the output signal is also sinusoidal,
with the same frequency, but different amplitude and phase.

$$y[t]=\sum_{i=0}^n h[i]x[t-i]$$

Since the term on the right is the sum of sinusoids of equal frequency,
the resulting output signal is also a sinusoid with the same frequency.

Sinusoids of different frequencies $\omega$ (measured in radians per sample) which are fed into the same LTI filter
may have their amplitudes (and phases) affected differently. 
For every $\omega$ that corresponds to a frequency bin in the DFT, 
the frequency response at $\omega$ is equal to the output amplitude when the input
is a sinusoid with frequency $\omega$ and amplitude $1$.

\pagebreak

\subsection{Discrete-Time Fourier Transform}
Unlike the DFT which can only be evaluated at certain frequences, 
the DTFT gives a function that can be evaluated at any frequency $\omega$ (measured in radians per sample) on the continuous spectrum.
$$DFT\left[\frac{n\omega}{2\pi}\right]=\sum_{t=0}^nx[t]e^{-i\omega t}$$
$$DTFT(e^{i\omega})=\sum_{t=0}^nx[t]e^{-i\omega t}$$

The DFT is essentially the DTFT sampled at the specific frequencies (1 to N/2 cycles per window).

\subsection{Frequency Response}
The frequency response of a LTI system as a function of frequency $\omega$ is equal
to the amount that the amplitude of a sinusoid with frequency $\omega$ would be scaled by when fed through the system.
The frequency response of the system is equal to the DTFT of the impulse response,
taking the magnitude of each phasor.

This is because convolving a signal with the impulse response (convolution in the time domain)
is equivalent to performing component-wise multiplication of the DFT of the signal with the DFT of the impulse response.
Therefore the DFT of the impulse response represents how much each frequency component of the signal will be scaled by
when the LTI system is applied.

This comes from the discrete version of the convolution theorem.

This can be generalised, where the frequency response can be calculated for continuous $\omega$ values 
not necessarily corresponding to any DFT frequency bin. This is just done using the DTFT.

\subsection{Filter Design}
Instead of using a system's impulse response to find its frequency response, 
you can use a desired frequency response and perform an IDFT to produce the 
kernel for a system that has that desired frequency response.

However for the purpose of making this implementation easier, I will just use 
perform low pass filtering using a moving average. A moving average will 
tend to attenuate high frequencies. A corresponding high pass filter kernel can be
produced by using linearity properties.

The moving average uses a rectangular kernel.
The frequency response of this filter can be found by using the DTFT of the rectangular kernel.
\pagebreak 

Suppose that the length of the rectangular kernel is $W$ samples. 
In other words, the kernel is $h$, where $h[t]=\frac{1}{W}$ for $0\leq t < W$, and $h[t]=0$ everywhere else.
Finding the DTFT of the kernel:
\begin{align*}
    DTFT(e^{i\omega})
    &= \sum_{t=0}^n h[t] e^{-i\omega t}\\
    &= \frac{1}{W} \sum_{t=0}^W e^{-i\omega t}\\
    &= \frac{1}{W} \frac{1-e^{-i\omega W }}{1-e^{i\omega }}\\
    &= \frac{1}{W} \frac{e^{-i\omega W /2}(e^{i\omega W /2}-e^{-i\omega W /2})}{e^{-i\omega t/2}(e^{i\omega /2}-e^{-i\omega /2})}\\
    &= \frac{1}{W} e^{-i\omega (W-1) /2} \frac{\sin (\omega W /2)}{\sin (\omega /2)}
\end{align*}

Taking the magnitude of both sides to find the frequency magnitude response gives
$$|DTFT(e^{i\omega})|=\frac{1}{W}\left|\frac{\sin (\omega W /2)}{\sin (\omega /2)}\right|$$

Below is a graph of the frequency magnitude response vs frequency (radians per sample).
The green graph is when $W=6$ and the red graph is when $W=5$.
\begin{center}\includegraphics[height=4cm]{assets/rectangledtft.png}\end{center}

As expected, in both cases, high frequencies are attenuated.
Also the wider the rectangle, the thinner the lobe of the frequency magnitude response,
thus less high frequencies are let through.

\pagebreak

\subsection{Implementation}
This time the FFT will be used to perform a convolution of the windowed input signal
with the kernel.

For these, I made new \verb|WindowProcessor| functor subclasses.
The first is the \verb|FConvLowpass| subclass.

\begin{verbatim}
struct FConvLowpass : public WindowProcessor {
    size_t width_;
    Transformer transformer_;
    std::vector<std::complex<double>> kernel_;

    FConvLowpass(size_t width, size_t win_size);

    std::vector<std::complex<double>> operator()(
        std::vector<std::complex<double>> const& signal
    ) override;
};
\end{verbatim}

This class is constructed with a \verb|win_size| parameter.
During the construction, the kernel vector is populated:

\begin{verbatim}
FConvLowpass::FConvLowpass(size_t width, size_t win_size) : 
width_(width), transformer_(win_size), kernel_(win_size, 0) {
    for (int i = 0; i < width; ++i) {
        kernel_[i] = 1/((double) width);
    }
}
\end{verbatim}

Throughout the lifetime of a \verb|FConvLowpass| object, 
this kernel vector is not modified.
Therefore we do not need to construct and populate a new kernel vector 
every time we want to perform a convolution.

Like all other \verb|WindowProcessor| objects, the address of a
\verb|FConvLowpass| object is passed in during the construction of a
\verb|StreamProcessor| object (dependency injection).
As audio data is inserted into the stream, this results in the
function call operator being called:

\begin{verbatim}
    // then process it using the window processing functor
    auto processed_window = win_processor->operator()(window);
\end{verbatim}

The \verb|FConvLowpass| class overrides the function call operator as shown below.

\begin{verbatim}
std::vector<std::complex<double>> FConvLowpass::operator()(
    std::vector<std::complex<double>> const& signal
) {
    return convolve(signal, kernel_, transformer_);
}
\end{verbatim}

\pagebreak

The convolve function takes two vectors of complex doubles of the same length.
Then it performs DFTs on both of them.
After this it performs component-wise multiplication, before finally
performing an IDFT to return the result of the convolution.

\begin{verbatim}
std::vector<std::complex<double>> convolve(
    std::vector<std::complex<double>> const& signal,
    std::vector<std::complex<double>> const& kernel,
    Transformer const& t
) {
    int n = signal.size();
    auto dft_signal = t.dft(signal);
    auto dft_kernel = t.dft(kernel);

    // component-wise multiplication
    for (int i = 0; i < n; ++i) {
        dft_signal[i] *= dft_kernel[i];
    }

    return t.idft(dft_signal);
}
\end{verbatim}

The \verb|FConvLowpass| functor just uses a rectangular kernel to perform
a moving average. 
The \verb|FConvHighpass| functor uses a kernel which is just the same rectangular
kernel subtracted from the delta function.

\begin{verbatim}
FConvHighpass::FConvHighpass(size_t width, size_t win_size) 
: width_(width), transformer_(win_size), kernel_(win_size, 0) {
    for (int i = 0; i < width; ++i) {
        kernel_[i] = -1/((double) width);
    }
    kernel_[0] += 1;
}
\end{verbatim}

This works because the filter defined by this kernel is just the
low pass filter subtracted from the identity filter, 
meaning that the low frequencies are removed, only allowing high frequencies to pass.

This is possible because convolving with the sum of two kernels is
equivalent to performing separate convolutions with the kernels and then
adding the resulting signals together.
